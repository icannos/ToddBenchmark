bert_scorer:
  (): bert_score.BERTScorer
  lang: "en"
  rescale_with_baseline: True
  model_type: "bert-base-uncased"

bleu_scorer:
  (): sacrebleu.BLEU
  trg_lang: ""
  effective_order: True

model: !import:llama-model model_configs.yml
tokenizer: !import:llama-tokenizer model_configs.yml

detectors:
  - (): Todd.T5QueryScorer
    batch_size: 8
    model: !import:t5-base-model model_configs.yml
    tokenizer: !import:t5-base-tokenizer model_configs.yml
  - (): Todd.BartQueryScorer
    batch_size: 8
    model: !import:bart-base-model model_configs.yml
    tokenizer: !import:bart-base-tokenizer model_configs.yml
  - (): Todd.BertQueryScorer
    batch_size: 8
    model: !import:bert-base-model model_configs.yml
    tokenizer: !import:bert-base-tokenizer model_configs.yml
  - (): Todd.ClassifierScorer
    chosen_state: "decoder_hidden_states"
    hidden_size: 2048
    batch_size: 8
    num_train_epochs: 10

  - (): Todd.MahalanobisScorer
    layers: [ -1 ]
    use_first_token_only: false
    chosen_state: "decoder_hidden_states"
#
##  - (): Todd.MahalanobisScorer
##    layers: [-1]
##    use_first_token_only: false
##    chosen_state: "encoder_hidden_states"
##  - (): Todd.MahalanobisScorer
##    layers: [ -1 ]
##    use_first_token_only: false
##    chosen_state: "decoder_hidden_states"
#
  - (): Todd.CosineProjectionScorer
    layers: [ -1 ]
    use_first_token_only: false
    chosen_state: "decoder_hidden_states"

experiment_args:
  (): scripts.configs.wrapper.ExperimentArgs
  output_dir: "output/"
  num_workers: 8
  num_return_sequences: 4
  seed: 42
  append: false
  device: "cuda"
  batch_size: 1
  validation_size: 64
  # test_size: 200
